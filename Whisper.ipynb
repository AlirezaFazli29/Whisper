{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlirezaFazli29/Whisper/blob/main/Whisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUsKr0XgknZj"
      },
      "source": [
        "# Whisper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmwQwCAvkun8"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcX2MmVRqKx_"
      },
      "outputs": [],
      "source": [
        "! pip install --upgrade pip\n",
        "! pip install torchinfo\n",
        "! pip install pydub\n",
        "! pip install hazm\n",
        "! pip install jiwer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "e5d8s2kSklzJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "from torchinfo import summary\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "import zipfile\n",
        "import gzip\n",
        "import glob\n",
        "from shutil import make_archive\n",
        "import hazm\n",
        "import string\n",
        "from jiwer import wer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZEyzVz3kzpz"
      },
      "source": [
        "## Default Device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvZDKkN6k2q2",
        "outputId": "92fa1bbd-62d1-4980-e448-e501cb07ae05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available(): print(torch.cuda.get_device_name())\n",
        "else: print('cpu')\n",
        "default_device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA2tVz8Sk6XT"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oD9G4JuNk6tZ",
        "outputId": "cf19bdf3-fa9a-45b1-9a9c-bccfee73a1fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "model_id = \"openai/whisper-large-v3\"\n",
        "batch_size = 16\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(pretrained_model_name_or_path=model_id).to(default_device)\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "pipe = pipeline(\"automatic-speech-recognition\",\n",
        "                model=model,\n",
        "                tokenizer=processor.tokenizer,\n",
        "                feature_extractor=processor.feature_extractor,\n",
        "                max_new_tokens=128,\n",
        "                chunk_length_s=30,\n",
        "                batch_size=batch_size,\n",
        "                return_timestamps=True,\n",
        "                device=default_device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkp-vkkUuqhs",
        "outputId": "45e4ef76-fedc-4120-f47f-f03e0dcc700e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "================================================================================\n",
              "Layer (type:depth-idx)                                  Param #\n",
              "================================================================================\n",
              "WhisperForConditionalGeneration                         --\n",
              "├─WhisperModel: 1-1                                     --\n",
              "│    └─WhisperEncoder: 2-1                              --\n",
              "│    │    └─Conv1d: 3-1                                 492,800\n",
              "│    │    └─Conv1d: 3-2                                 4,916,480\n",
              "│    │    └─Embedding: 3-3                              (1,920,000)\n",
              "│    │    └─ModuleList: 3-4                             629,637,120\n",
              "│    │    └─LayerNorm: 3-5                              2,560\n",
              "│    └─WhisperDecoder: 2-2                              --\n",
              "│    │    └─Embedding: 3-6                              66,388,480\n",
              "│    │    └─WhisperPositionalEmbedding: 3-7             573,440\n",
              "│    │    └─ModuleList: 3-8                             839,557,120\n",
              "│    │    └─LayerNorm: 3-9                              2,560\n",
              "├─Linear: 1-2                                           66,388,480\n",
              "================================================================================\n",
              "Total params: 1,609,879,040\n",
              "Trainable params: 1,607,959,040\n",
              "Non-trainable params: 1,920,000\n",
              "================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxMHRzKbqi0d"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_file_path = './Recordings.zip'\n",
        "extracted_folder_path = './Recordings'"
      ],
      "metadata": {
        "id": "oOTgpzp_tHnx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if (os.path.exists(extracted_folder_path) and os.path.isdir(extracted_folder_path)):\n",
        "    print(f'folder {extracted_folder_path} exists')\n",
        "else:\n",
        "    with zipfile.ZipFile(zip_file_path, mode='r') as zip_ref:\n",
        "        zip_ref.extractall(extracted_folder_path)\n",
        "    print('files extracted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kN0xswd7tTLs",
        "outputId": "258a496a-46f6-4a55-a3fe-7dd5500242ee"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "files extracted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paths = glob.glob(extracted_folder_path+'/*')\n",
        "len(paths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5NwcnQVt4N3",
        "outputId": "731ff9eb-f17a-42a1-ea98-7b015e187494"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "106"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = list(pd.read_csv('Transcriptions.csv', header=None)[1])"
      ],
      "metadata": {
        "id": "hQmAadjgrIdq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "un2oBA52k7hi"
      },
      "source": [
        "## Using the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = [None for _ in range(len(paths))]\n",
        "\n",
        "for i, path in enumerate(paths):\n",
        "\n",
        "    audio = AudioSegment.from_file(path)\n",
        "    waveform = np.array(audio.normalize().set_channels(1).get_array_of_samples())\n",
        "    waveform = waveform/max(waveform)\n",
        "    sr = audio.frame_rate\n",
        "    results[i] = pipe({'array': waveform, 'sampling_rate':sr})"
      ],
      "metadata": {
        "id": "ixQSpupKvH_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Transcriptions"
      ],
      "metadata": {
        "id": "S5DT83740nBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transcriptions_folder = './Transcriptions'"
      ],
      "metadata": {
        "id": "IBabj1SI0y1G"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if (os.path.exists(transcriptions_folder) and os.path.isdir(transcriptions_folder)):\n",
        "    print(f'folder {transcriptions_folder} exists')\n",
        "else:\n",
        "    os.mkdir(transcriptions_folder)\n",
        "    print('Folder created')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tu55xUs3vnNT",
        "outputId": "5cd27575-8025-4b81-a6a1-e52a4929c8c8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transcription_paths = [transcriptions_folder+'/'+path.split('/')[-1].split('.')[0]+'.txt' for path in paths]"
      ],
      "metadata": {
        "id": "lx2R2zl11tXY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, path in enumerate(transcription_paths):\n",
        "    text_file = open(path, \"w\")\n",
        "    text_file.write(results[i]['text'])\n",
        "    text_file.close()"
      ],
      "metadata": {
        "id": "0-870hPT2nvf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_archive(transcriptions_folder, 'zip', transcriptions_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "g6Gudn945Xtk",
        "outputId": "40643283-bf46-41e0-9fe5-074514f8698a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Transcriptions.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WER"
      ],
      "metadata": {
        "id": "eK6o9TCRrt3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer = hazm.Normalizer()\n",
        "punc = string.punctuation + '،' + '؛'"
      ],
      "metadata": {
        "id": "lkLcQI883lCT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WER = [None for _ in range(len(transcription_paths))]\n",
        "for i, path in enumerate(transcription_paths):\n",
        "    num = int(path.split(' ')[-1].split('.')[0][1:-1]) - 1\n",
        "    reference = ''.join([char for char in texts[num] if char not in punc])\n",
        "    reference = normalizer.normalize(reference)\n",
        "    hypothesis = ''.join([char for char in results[i]['text'] if char not in punc])\n",
        "    hypothesis = normalizer.normalize(hypothesis)\n",
        "    WER[i] = wer(reference, hypothesis)\n",
        "\n",
        "print(f'The average WER is equal tt {sum(WER)/len(WER)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2uN1WSS3Jmb",
        "outputId": "e646da92-2ead-4928-90c8-f12b50fca2bc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The average WER is equal tt 0.24018175581077722\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNYAFXEiwzFPSwZ2ajS5pRS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}